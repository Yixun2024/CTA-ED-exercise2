---
title: "exercise"
author: "yixun"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

```{r,message=F}
install.packages("kableExtra")
install.packages("textdata")
library(kableExtra)
library(tidyverse)
library(readr)
library(stringr)
library(tidytext)
library(quanteda)
library(textdata)
```

```{r, message=F}
install.packages("academictwitteR")
library(academictwitteR)
```
```{r}
getwd()
```

```{r, eval = F}
tweets  <- readRDS(gzcon(url("https://github.com/cjbarrie/CTA-ED/blob/main/data/sentanalysis/newstweets.rds?raw=true")))
```

```{r}
head(tweets)
names(tweets)
```

```{r}
tweets <- tweets %>%
  select(user_username, text, created_at, user_name,
         retweet_count, like_count, quote_count) %>%
  rename(username = user_username,
         newspaper = user_name,
         tweet = text)
```

```{r, echo=F}
tweets %>%
  arrange(newspaper) %>%
  tail(5) %>%
  kbl() %>%
  kable_styling(c("striped", "hover", "codensed", "responsive"))
```

```{r}
tidy_tweets <- tweets %>%
  mutate(desc = tolower(tweet)) %>%
  unnest_tokens(word, desc) %>%
  filter(str_detect(word,"[a-z]"))
```

```{r}
tidy_tweets <- tidy_tweets %>%
  filter(!word %in% stop_words$word)
```

```{r}
get_sentiments("afinn")
```

```{r}
get_sentiments("bing")
```

```{r}
get_sentiments("nrc")
```

```{r}
nrc_fear <- get_sentiments("nrc") %>%
  filter(sentiment == "fear")

tidy_tweets %>%
  inner_join(nrc_fear) %>%
  count(word, sort = TRUE)
```

```{r}
tidy_tweets <- tidy_tweets %>%
arrange(username)

tidy_tweets$order <- 1:nrow(tidy_tweets)
```

```{r}
tweets_nrc_sentiment <- tidy_tweets %>%
  inner_join(get_sentiments("nrc")) %>%
  count(username, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative)

tweets_nrc_sentiment %>%
  ggplot(aes(username, sentiment)) +
  geom_point(alpha = 0.5) +
  geom_smooth(method = loess, alpha = 0.25)
```

```{r}
tidy_tweets %>%
  inner_join(get_sentiments("bing")) %>%
  count(username, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative) %>%
  ggplot(aes(username, sentiment)) +
  geom_point(alpha=0.5) +
  geom_smooth(method= loess, alpha=0.25) +
  ylab("bing sentiment")

tidy_tweets %>%
  inner_join(get_sentiments("nrc")) %>%
  count(username, sentiment) %>%
  spread(sentiment, n, fill = 0) %>%
  mutate(sentiment = positive - negative) %>%
  ggplot(aes(username, sentiment)) +
  geom_point(alpha=0.5) +
  geom_smooth(method= loess, alpha=0.25) +
  ylab("nrc sentiment")

tidy_tweets %>%
  inner_join(get_sentiments("afinn")) %>%
  group_by(username) %>% 
  summarise(sentiment = sum(value)) %>% 
  ggplot(aes(username, sentiment)) +
  geom_point(alpha=0.5) +
  geom_smooth(method= loess, alpha=0.25) +
  ylab("afinn sentiment")
```

```{r}
word <- c('out','leave','abandon','quarantine','isolation','lockdown','shutdown','close','online','remote')

value <- c(1,1,1,1,1,1,1,1,1,1)
newdict <- data.frame(word, value)
newdict
```

```{r}
tidy_tweets %>%
  inner_join(newdict) %>%
  group_by(username) %>%
  summarise(newwords = sum(value)) %>%
  ggplot(aes(username,newwords)) +
  geom_bar(stat = "identity") +
  ylab("lockdown words")
```

```{r}
newdict <- c('out','leave','abandon','quarantine','isolation','lockdown','shutdown','close','online','remote')

totals <- tidy_tweets %>%
  mutate(obs=1) %>%
  group_by(username) %>%
  summarise(sum_words = sum(obs))

tidy_tweets %>%
  mutate(obs=1) %>%
  filter(grepl(paste0(newdict, collapse = "|"),word, ignore.case = T)) %>%
  group_by(username) %>%
  summarise(sum_nwords = sum(obs)) %>%
  full_join(totals, word, by="username") %>%
  mutate(sum_nwords= ifelse(is.na(sum_nwords), 0, sum_nwords),
         pctnwords = sum_nwords/sum_words) %>%
  ggplot(aes(username, pctnwords)) +
  geom_point(alpha=0.5) +
  geom_smooth(method= loess, alpha=0.25) +
  xlab("Username") + ylab("% lockdown words")
```


```{r}
tweet_corpus <- corpus(tweets, text_field = "tweet", docvars = "newspaper")
```

```{r}
toks_news <- tokens(tweet_corpus, remove_punct = TRUE)
```

```{r}
data_dictionary_LSD2015_pos_neg <- data_dictionary_LSD2015[1:2]

toks_news_lsd <- tokens_lookup(toks_news, dictionary = data_dictionary_LSD2015_pos_neg)
```

```{r}
dfmat_news_lsd <- dfm(toks_news_lsd) %>%
  dfm_group(groups = newspaper)

matplot(dfmat_news_lsd$newspaper, dfmat_news_lsd, type = "l", lty = 1, col = 1:2, 
        xlim = c(1, nrow(dfmat_news_lsd)),
        ylab = "Frequency",
        xlab = "")
grid()
legend("topleft", col = 1:2, legend = colnames(dfmat_news_lsd), lty = 1, bg = "white")


plot(dfmat_news_lsd$newspaper, dfmat_news_lsd[,"positive"] - dfmat_news_lsd[,"negative"],
     xlim = c(1, nrow(dfmat_news_lsd)),
     type = "l", ylab = "Sentiment", xlab = "")
grid()
abline(h = 0, lty = 2)
```
